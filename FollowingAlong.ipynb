{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the data\n",
    "\n",
    "In the blog post I'm following it outputs the following information: \n",
    "\n",
    "```\n",
    "1823250 English words.\n",
    "227 unique English words.\n",
    "10 Most common words in the English dataset:\n",
    "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
    "\n",
    "1961295 French words.\n",
    "355 unique French words.\n",
    "10 Most common words in the French dataset:\n",
    "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n",
    "```\n",
    "\n",
    "I want to add how many phrases I hae but to generally create this output here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from tools import *\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next two cells are because I had to manipulate the data a little from pre-processing. I have resaved it and now the load_data() line should work"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/eng_fren_full.tsv', sep='\\t')\n",
    "df, id2fren, id2eng, y_fren, X_eng = nlp_to_nums(df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "id2fren.save('data/Dictionaries/fren')\n",
    "id2eng.save('data/Dictionaries/eng')\n",
    "df.drop('Unnamed: 0', axis=1).to_csv('data/processed_full.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, id2eng, id2fren, X_eng, y_fren = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "      <th>french_tokens</th>\n",
       "      <th>english_tokens</th>\n",
       "      <th>english_bow</th>\n",
       "      <th>french_bow</th>\n",
       "      <th>english_padded</th>\n",
       "      <th>french_padded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new jersey is sometimes quiet during autumn , ...</td>\n",
       "      <td>new jersey est parfois calme pendant l' automn...</td>\n",
       "      <td>[new, jersey, est, parfois, calme, pendant, l,...</td>\n",
       "      <td>[new, jersey, is, sometimes, quiet, during, au...</td>\n",
       "      <td>[8, 7, 5, 11, 9, 3, 2, 0, 6, 5, 10, 4, 1]</td>\n",
       "      <td>[10, 7, 4, 11, 2, 12, 8, 0, 5, 6, 4, 9, 3, 1]</td>\n",
       "      <td>[8, 7, 5, 11, 9, 3, 2, 0, 6, 5, 10, 4, 1, -1, ...</td>\n",
       "      <td>[10, 7, 4, 11, 2, 12, 8, 0, 5, 6, 4, 9, 3, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the united states is usually chilly during jul...</td>\n",
       "      <td>les états-unis est généralement froid en juill...</td>\n",
       "      <td>[les, états, unis, est, généralement, froid, e...</td>\n",
       "      <td>[the, united, states, is, usually, chilly, dur...</td>\n",
       "      <td>[17, 18, 16, 5, 19, 12, 3, 14, 0, 6, 5, 19, 13...</td>\n",
       "      <td>[18, 21, 20, 4, 15, 13, 3, 17, 5, 6, 14, 16, 3...</td>\n",
       "      <td>[17, 18, 16, 5, 19, 12, 3, 14, 0, 6, 5, 19, 13...</td>\n",
       "      <td>[18, 21, 20, 4, 15, 13, 3, 17, 5, 6, 14, 16, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>california is usually quiet during march , and...</td>\n",
       "      <td>california est généralement calme en mars , et...</td>\n",
       "      <td>[california, est, généralement, calme, en, mar...</td>\n",
       "      <td>[california, is, usually, quiet, during, march...</td>\n",
       "      <td>[20, 5, 19, 9, 3, 23, 0, 6, 5, 19, 21, 4, 22]</td>\n",
       "      <td>[22, 4, 15, 2, 3, 25, 5, 6, 4, 15, 23, 3, 24]</td>\n",
       "      <td>[20, 5, 19, 9, 3, 23, 0, 6, 5, 19, 21, 4, 22, ...</td>\n",
       "      <td>[22, 4, 15, 2, 3, 25, 5, 6, 4, 15, 23, 3, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the united states is sometimes mild during jun...</td>\n",
       "      <td>les états-unis est parfois légère en juin , et...</td>\n",
       "      <td>[les, états, unis, est, parfois, légère, en, j...</td>\n",
       "      <td>[the, united, states, is, sometimes, mild, dur...</td>\n",
       "      <td>[17, 18, 16, 5, 11, 25, 3, 22, 0, 6, 5, 24, 4,...</td>\n",
       "      <td>[18, 21, 20, 4, 11, 27, 3, 24, 5, 6, 26, 13, 3...</td>\n",
       "      <td>[17, 18, 16, 5, 11, 25, 3, 22, 0, 6, 5, 24, 4,...</td>\n",
       "      <td>[18, 21, 20, 4, 11, 27, 3, 24, 5, 6, 26, 13, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>your least liked fruit is the grape , but my l...</td>\n",
       "      <td>votre moins aimé fruit est le raisin , mais mo...</td>\n",
       "      <td>[votre, moins, aimé, fruit, est, le, raisin, m...</td>\n",
       "      <td>[your, least, liked, fruit, is, the, grape, bu...</td>\n",
       "      <td>[34, 31, 32, 29, 5, 17, 30, 28, 33, 31, 32, 5,...</td>\n",
       "      <td>[38, 34, 29, 30, 4, 32, 37, 33, 35, 34, 29, 4,...</td>\n",
       "      <td>[34, 31, 32, 29, 5, 17, 30, 28, 33, 31, 32, 5,...</td>\n",
       "      <td>[38, 34, 29, 30, 4, 32, 37, 33, 35, 34, 29, 4,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  new jersey is sometimes quiet during autumn , ...   \n",
       "1  the united states is usually chilly during jul...   \n",
       "2  california is usually quiet during march , and...   \n",
       "3  the united states is sometimes mild during jun...   \n",
       "4  your least liked fruit is the grape , but my l...   \n",
       "\n",
       "                                              french  \\\n",
       "0  new jersey est parfois calme pendant l' automn...   \n",
       "1  les états-unis est généralement froid en juill...   \n",
       "2  california est généralement calme en mars , et...   \n",
       "3  les états-unis est parfois légère en juin , et...   \n",
       "4  votre moins aimé fruit est le raisin , mais mo...   \n",
       "\n",
       "                                       french_tokens  \\\n",
       "0  [new, jersey, est, parfois, calme, pendant, l,...   \n",
       "1  [les, états, unis, est, généralement, froid, e...   \n",
       "2  [california, est, généralement, calme, en, mar...   \n",
       "3  [les, états, unis, est, parfois, légère, en, j...   \n",
       "4  [votre, moins, aimé, fruit, est, le, raisin, m...   \n",
       "\n",
       "                                      english_tokens  \\\n",
       "0  [new, jersey, is, sometimes, quiet, during, au...   \n",
       "1  [the, united, states, is, usually, chilly, dur...   \n",
       "2  [california, is, usually, quiet, during, march...   \n",
       "3  [the, united, states, is, sometimes, mild, dur...   \n",
       "4  [your, least, liked, fruit, is, the, grape, bu...   \n",
       "\n",
       "                                         english_bow  \\\n",
       "0          [8, 7, 5, 11, 9, 3, 2, 0, 6, 5, 10, 4, 1]   \n",
       "1  [17, 18, 16, 5, 19, 12, 3, 14, 0, 6, 5, 19, 13...   \n",
       "2      [20, 5, 19, 9, 3, 23, 0, 6, 5, 19, 21, 4, 22]   \n",
       "3  [17, 18, 16, 5, 11, 25, 3, 22, 0, 6, 5, 24, 4,...   \n",
       "4  [34, 31, 32, 29, 5, 17, 30, 28, 33, 31, 32, 5,...   \n",
       "\n",
       "                                          french_bow  \\\n",
       "0      [10, 7, 4, 11, 2, 12, 8, 0, 5, 6, 4, 9, 3, 1]   \n",
       "1  [18, 21, 20, 4, 15, 13, 3, 17, 5, 6, 14, 16, 3...   \n",
       "2      [22, 4, 15, 2, 3, 25, 5, 6, 4, 15, 23, 3, 24]   \n",
       "3  [18, 21, 20, 4, 11, 27, 3, 24, 5, 6, 26, 13, 3...   \n",
       "4  [38, 34, 29, 30, 4, 32, 37, 33, 35, 34, 29, 4,...   \n",
       "\n",
       "                                      english_padded  \\\n",
       "0  [8, 7, 5, 11, 9, 3, 2, 0, 6, 5, 10, 4, 1, -1, ...   \n",
       "1  [17, 18, 16, 5, 19, 12, 3, 14, 0, 6, 5, 19, 13...   \n",
       "2  [20, 5, 19, 9, 3, 23, 0, 6, 5, 19, 21, 4, 22, ...   \n",
       "3  [17, 18, 16, 5, 11, 25, 3, 22, 0, 6, 5, 24, 4,...   \n",
       "4  [34, 31, 32, 29, 5, 17, 30, 28, 33, 31, 32, 5,...   \n",
       "\n",
       "                                       french_padded  \n",
       "0  [10, 7, 4, 11, 2, 12, 8, 0, 5, 6, 4, 9, 3, 1, ...  \n",
       "1  [18, 21, 20, 4, 15, 13, 3, 17, 5, 6, 14, 16, 3...  \n",
       "2  [22, 4, 15, 2, 3, 25, 5, 6, 4, 15, 23, 3, 24, ...  \n",
       "3  [18, 21, 20, 4, 11, 27, 3, 24, 5, 6, 26, 13, 3...  \n",
       "4  [38, 34, 29, 30, 4, 32, 37, 33, 35, 34, 29, 4,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need a flattened list of all the words to pass into counter\n",
    "english_word_list = [l for sublist in data['english_tokens'] for l in sublist]\n",
    "french_word_list = [l for sublist in data['french_tokens'] for l in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_counter = Counter(english_word_list)\n",
    "fren_counter = Counter(french_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2511216 English words.\n",
      "13482 unique English Words.\n",
      "10 most common english words in the data:\n",
      "\"is\" \"the\" \"it\" \"in\" \"during\" \"but\" \"i\" \"and\" \"you\" \"never\"\n",
      "\n",
      "2766892 French words.\n",
      "23242 unique french words.\n",
      "10 most common french words:\n",
      "\"est\" \"en\" \"il\" \"la\" \"mais\" \"l\" \"et\" \"les\" \"le\" \"de\"\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(english_word_list)} English words.')\n",
    "print(f'{len(eng_counter)} unique English Words.')\n",
    "print(f'10 most common english words in the data:')\n",
    "print('\"' + '\" \"'.join(list(zip(*eng_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print(f'{len(french_word_list)} French words.')\n",
    "print(f'{len(fren_counter)} unique french words.')\n",
    "print('10 most common french words:')\n",
    "print('\"' + '\" \"'.join(list(zip(*fren_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok so I have slightly more complicated data\n",
    "I'm mostly going to still follow the guide and 'create my own' embedding, because that will be *slightly* easier for the first round (just following along) however like the guide says I want to go back and impliment someone else's embedding to better capture this vocabulary and make it exportable. \n",
    "\n",
    "In the next section the guide has a lot of work done around tokenization. I'm going to assume my tokenization worked properly, for this version I'm not going to go back and do any additional cleaning and not worry about all the punctuation.\n",
    "\n",
    "Additional cleaning is an area that I could improve this project in the future. I'm acknowledging that I'm feeding my neural network garbage and as such will get garbage back out. \n",
    "\n",
    "Since I'm just copying the project from the internet there is an argument to be made that I should just use the same data but I want to have some personal flare \n",
    "\n",
    "It looks like my pre-processing does most of the same thing as theirs does. Theres just an issue of needing to be reshaped. I'm going to see what I can do to get my data into the right shape and be left with an X and y variable that I can pass into a train_test_split. \n",
    "\n",
    "These edits need to be made in my tools function that loads the data. Return the full DF and an X and y value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#to manipulate the data for the NN I need everything into a numpy array \n",
    "#this converts things appropriately\n",
    "#This cell has been added to load_data()\n",
    "X_eng = np.vstack(data['english_padded'].values)\n",
    "y_fren = np.vstack(data['french_padded'].values)\n",
    "y_fren.shape, X_eng.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the reshaping that I need to do for the NN\n",
    "# This cell has been added to load_data()\n",
    "y_fren = y_fren.reshape(*y_fren.shape, 1)\n",
    "X_eng = X_eng.reshape(*X_eng.shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eng, X_test_eng, y_train_fren, y_test_fren = train_test_split(X_eng, y_fren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'jersey',\n",
       " 'est',\n",
       " 'parfois',\n",
       " 'calme',\n",
       " 'pendant',\n",
       " 'l',\n",
       " 'automne',\n",
       " 'et',\n",
       " 'il',\n",
       " 'est',\n",
       " 'neigeux',\n",
       " 'en',\n",
       " 'avril']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_french(data['french_padded'][0], id2fren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "This is a simple RNN that that is just here to be a baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_model(input_shape, output_length, eng_vocab_size, french_vocab_size): \n",
    "    #hyperparameters\n",
    "    learning_rate = .005\n",
    "        \n",
    "    # TODO: Build the layers\n",
    "    model = Sequential()\n",
    "    model.add(GRU(256, input_shape=input_shape[1:], return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation='softmax'))) \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_rnn = simple_model(X_train_eng.shape, 60, len(id2eng), len(id2fren))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13482, 23242)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2eng), len(id2fren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 60, 256)           198144    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 1024)          263168    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 1024)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 60, 23242)         23823050  \n",
      "=================================================================\n",
      "Total params: 24,284,362\n",
      "Trainable params: 24,284,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170696 samples, validate on 42675 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "simple_rnn.fit(X_train_eng, y_train_fren, batch_size=1024, epochs=10, validation_split=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First learning experience \n",
    "well it looks like my input and output have to be of the same length. I have gone back and updated my process data function accordingly and will be re-producing the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213371, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TranslatorNet",
   "language": "python",
   "name": "translatornet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
